{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb60b6b-3589-42ac-9971-dc8c9af56562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from astropy.table import Table, vstack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2267c278-4985-447e-94ec-f273d1abf498",
   "metadata": {},
   "outputs": [],
   "source": [
    "mSN = [1e9/Table.read('/pscratch/sd/h/hebina/AbacusLBG/ibis_tertiary44/LAE_auto_v2/hod/matter_AbacusSummit_high_c000_ph100_z2.5.fits')['x'].size,\n",
    "       1e9/Table.read('/pscratch/sd/h/hebina/AbacusLBG/ibis_tertiary44/LAE_auto_v2/hod/matter_AbacusSummit_high_c000_ph100_z3.0.fits')['x'].size]\n",
    "mSN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b8c9b3-2d93-4017-b555-17be2ad723e7",
   "metadata": {},
   "source": [
    "# This code manually takes out shot noise "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468381bb-d715-4be8-a719-f713e6449456",
   "metadata": {},
   "source": [
    "# $z=3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71bd23d6-6eb1-4197-9298-e54e467ba5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = 3.\n",
    "ihod = 1\n",
    "kpow = 1.25 # manual adjustment to covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f00907d5-75fa-4d8c-9fa5-4fd4cde6951a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.0, 12.7, 0.66, 1, 0.33, 0, 0, 0, 0, 0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "(7500,) (7500,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ff = open('/pscratch/sd/h/hebina/AbacusLBG/ibis_tertiary44/LAE_auto/lae_clustering_concat_c000_ph100_s_zcv.json')\n",
    "ff = open('/pscratch/sd/h/hebina/AbacusLBG/ibis_tertiary44/LAE_auto_v2/hod/lae_clustering_c000_ph100_z3.0_s_zcv.json')\n",
    "# ff = open(self.datfn)\n",
    "simdata = json.load(ff)\n",
    "sim_k = np.array(simdata['k'])\n",
    "k = np.array(simdata['k'])\n",
    "Nk = len(k)\n",
    "Nmu = 50\n",
    "mu = np.linspace(0.,1.,Nmu)\n",
    "MU = np.tile(mu,Nk)\n",
    "dmu = list(mu[1:]-mu[:-1])\n",
    "dmu.append(dmu[-1])\n",
    "dmu = np.array(dmu)\n",
    "\n",
    "dk = list(k[1:]-k[:-1])\n",
    "dk.insert(0,dk[0])\n",
    "dk = np.array(dk)\n",
    "k = np.repeat(k,Nmu)\n",
    "dk = np.repeat(dk,Nmu)\n",
    "dmu = np.tile(dmu,Nk)\n",
    "\n",
    "print(simdata['mocks'][ihod]['hod'])\n",
    "dd = [simdata['mocks'][ihod]['pk0'],simdata['mocks'][ihod]['pk2']]\n",
    "dd = np.array(dd).T\n",
    "\n",
    "# take out shot noise\n",
    "true_SN = 1e9/min(simdata['mocks'][ihod]['nobj'],1e7)\n",
    "\n",
    "dvec = np.array([np.repeat(dd[:,0],Nmu),np.repeat(dd[:,1],Nmu)])\n",
    "d_pkmu = dvec[0]+0.5*(3*MU**2-1)*dvec[1]\n",
    "d_pkmu -= true_SN\n",
    "print(k.shape,d_pkmu.shape)\n",
    "Vsurvey = (1e3)**3\n",
    "\n",
    "prefactor = (2.*np.pi**2.) / (dk*dmu*Vsurvey*k**2.) * k**kpow\n",
    "Cov = prefactor*2*d_pkmu**2\n",
    "# constraints = forecast1.compute_wedge(z,kmin=kmin)*forecast1.kmax_constraint(z,kmax_knl)\n",
    "# constraints *= (forecast1.k > kmin)\n",
    "knl  = 0.5\n",
    "kmin = 0.003\n",
    "kmax = knl\n",
    "\n",
    "\n",
    "k_constraint = (k>kmin)*(k<kmax)\n",
    "Cov += 1e-20\n",
    "Cinv = 1/Cov\n",
    "Cinv *= k_constraint\n",
    "# Cinv = np.einsum('i,j,ij->ij',k_constraint,k_constraint,Cinv)\n",
    "\n",
    "# Cinv = np.ones(dvec.shape)\n",
    "\n",
    "\n",
    "file_name = 'data/sim_gg.json'\n",
    "\n",
    "save_dict = {'z':zz,'space':'rsd','kmin':kmin,'kmax':kmax,'Cov':Cov.tolist(),'Cinv':Cinv.tolist(),\n",
    "             'd_pkmu':d_pkmu.tolist(),'k':sim_k.tolist(),'mu':mu.tolist(),'d_ell':dd.tolist()}\n",
    "# Save array to JSON file\n",
    "with open(file_name, 'w') as json_file:\n",
    "    json.dump(save_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abb02346-42be-4c9a-b495-33d815655255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.0, 12.7, 0.66, 1, 0.33, 0, 0, 0, 0, 0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "(7500,) (7500,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ff = open('/pscratch/sd/h/hebina/AbacusLBG/ibis_tertiary44/LAE_auto/lae_clustering_concat_c000_ph100_s_zcv.json')\n",
    "ff = open('/pscratch/sd/h/hebina/AbacusLBG/ibis_tertiary44/LAE_auto_v2/hod/lae_clustering_c000_ph100_z3.0_r_zcv.json')\n",
    "# ff = open(self.datfn)\n",
    "simdata = json.load(ff)\n",
    "sim_k = np.array(simdata['k'])\n",
    "k = np.array(simdata['k'])\n",
    "Nk = len(k)\n",
    "Nmu = 50\n",
    "mu = np.linspace(0.,1.,Nmu)\n",
    "MU = np.tile(mu,Nk)\n",
    "dmu = list(mu[1:]-mu[:-1])\n",
    "dmu.append(dmu[-1])\n",
    "dmu = np.array(dmu)\n",
    "\n",
    "dk = list(k[1:]-k[:-1])\n",
    "dk.insert(0,dk[0])\n",
    "dk = np.array(dk)\n",
    "k = np.repeat(k,Nmu)\n",
    "dk = np.repeat(dk,Nmu)\n",
    "dmu = np.tile(dmu,Nk)\n",
    "\n",
    "print(simdata['mocks'][ihod]['hod'])\n",
    "dd = [simdata['mocks'][ihod]['pk0'],simdata['mocks'][ihod]['pk2']]\n",
    "dd = np.array(dd).T\n",
    "\n",
    "true_SN = 1e9/min(simdata['mocks'][ihod]['nobj'],1e7)\n",
    "\n",
    "dvec = np.array([np.repeat(dd[:,0],Nmu),np.repeat(dd[:,1],Nmu)])\n",
    "d_pkmu = dvec[0]+0.5*(3*MU**2-1)*dvec[1]\n",
    "d_pkmu -= true_SN\n",
    "print(k.shape,d_pkmu.shape)\n",
    "Vsurvey = (1e3)**3\n",
    "\n",
    "prefactor = (2.*np.pi**2.) / (dk*dmu*Vsurvey*k**2.) * k**kpow\n",
    "Cov = prefactor*2*d_pkmu**2\n",
    "# constraints = forecast1.compute_wedge(z,kmin=kmin)*forecast1.kmax_constraint(z,kmax_knl)\n",
    "# constraints *= (forecast1.k > kmin)\n",
    "knl  = 0.5\n",
    "kmin = 0.003\n",
    "kmax = knl\n",
    "\n",
    "\n",
    "k_constraint = (k>kmin)*(k<kmax)\n",
    "Cov += 1e-20\n",
    "Cinv = 1/Cov\n",
    "Cinv *= k_constraint\n",
    "# Cinv = np.einsum('i,j,ij->ij',k_constraint,k_constraint,Cinv)\n",
    "\n",
    "# Cinv = np.ones(dvec.shape)\n",
    "\n",
    "\n",
    "file_name = 'data/sim_gg_real.json'\n",
    "\n",
    "save_dict = {'z':zz,'space':'rsd','kmin':kmin,'kmax':kmax,'Cov':Cov.tolist(),'Cinv':Cinv.tolist(),\n",
    "             'd_pkmu':d_pkmu.tolist(),'k':sim_k.tolist(),'mu':mu.tolist(),'d_ell':dd.tolist()}\n",
    "# Save array to JSON file\n",
    "with open(file_name, 'w') as json_file:\n",
    "    json.dump(save_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cd0cbfb-adf5-45d3-8d4a-33e1959319d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.0, 12.7, 0.66, 1, 0.33, 0, 0, 0, 0, 0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "(2500,) (2500,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ff = open('/pscratch/sd/h/hebina/AbacusLBG/ibis_tertiary44/LAE_auto/lae_clustering_concat_c000_ph100_s_zcv.json')\n",
    "ff = open('/pscratch/sd/h/hebina/AbacusLBG/ibis_tertiary44/LAE_auto_v2/hod/lae_clustering_c000_ph100_z3.0_r_gm.json')\n",
    "# ff = open(self.datfn)\n",
    "simdata = json.load(ff)\n",
    "sim_k = np.array(simdata['k'])\n",
    "k = np.array(simdata['k'])\n",
    "Nk = len(k)\n",
    "Nmu = 50\n",
    "mu = np.linspace(0.,1.,Nmu)\n",
    "MU = np.tile(mu,Nk)\n",
    "dmu = list(mu[1:]-mu[:-1])\n",
    "dmu.append(dmu[-1])\n",
    "dmu = np.array(dmu)\n",
    "\n",
    "dk = list(k[1:]-k[:-1])\n",
    "dk.insert(0,dk[0])\n",
    "dk = np.array(dk)\n",
    "k = np.repeat(k,Nmu)\n",
    "dk = np.repeat(dk,Nmu)\n",
    "dmu = np.tile(dmu,Nk)\n",
    "\n",
    "print(simdata['mocks'][ihod]['hod'])\n",
    "dd = [simdata['mocks'][ihod]['pk0'],simdata['mocks'][ihod]['pk2']]\n",
    "dd = np.array(dd).T\n",
    "\n",
    "# dvec = np.array([np.repeat(dd[:,0],Nmu),np.repeat(dd[:,1],Nmu),np.repeat(dd[:,2],Nmu)])\n",
    "# d_pkmu = dvec[0]+0.5*(3*MU**2-1)*dvec[1]+0.125*(35*MU**4-30*MU**2+3)*dvec[2]\n",
    "dvec = np.array([np.repeat(dd[:,0],Nmu),np.repeat(dd[:,1],Nmu)])\n",
    "d_pkmu = dvec[0]+0.5*(3*MU**2-1)*dvec[1]\n",
    "print(k.shape,d_pkmu.shape)\n",
    "Vsurvey = (1e3)**3\n",
    "\n",
    "prefactor = (2.*np.pi**2.) / (dk*dmu*Vsurvey*k**2.) * k**kpow\n",
    "Cov = prefactor*2*d_pkmu**2\n",
    "# constraints = forecast1.compute_wedge(z,kmin=kmin)*forecast1.kmax_constraint(z,kmax_knl)\n",
    "# constraints *= (forecast1.k > kmin)\n",
    "knl  = 0.5\n",
    "kmin = 0.003\n",
    "kmax = knl\n",
    "\n",
    "\n",
    "k_constraint = (k>kmin)*(k<kmax)\n",
    "Cov += 1e-20\n",
    "Cinv = 1/Cov\n",
    "Cinv *= k_constraint\n",
    "# Cinv = np.einsum('i,j,ij->ij',k_constraint,k_constraint,Cinv)\n",
    "\n",
    "# Cinv = np.ones(dvec.shape)\n",
    "\n",
    "file_name = 'data/sim_gm.json'\n",
    "\n",
    "save_dict = {'z':zz,'space':'rsd','kmin':kmin,'kmax':kmax,'Cov':Cov.tolist(),'Cinv':Cinv.tolist(),\n",
    "             'd_pkmu':d_pkmu.tolist(),'k':sim_k.tolist(),'mu':mu.tolist(),'d_ell':dd.tolist()}\n",
    "# Save array to JSON file\n",
    "with open(file_name, 'w') as json_file:\n",
    "    json.dump(save_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e66027b-7cf5-40de-878d-cfe2ceba3b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.25, 11.948970004336019, 0.66, 1, 0.66, 0, 0, 0, 0, 0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "(2500,) (2500,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ff = open('/pscratch/sd/h/hebina/AbacusLBG/ibis_tertiary44/LAE_auto/lae_clustering_concat_c000_ph100_s_zcv.json')\n",
    "ff = open('/pscratch/sd/h/hebina/AbacusLBG/ibis_tertiary44/LAE_auto_v2/hod/lae_clustering_c000_ph100_z3.0_r_mm.json')\n",
    "# ff = open(self.datfn)\n",
    "simdata = json.load(ff)\n",
    "sim_k = np.array(simdata['k'])\n",
    "k = np.array(simdata['k'])\n",
    "Nk = len(k)\n",
    "Nmu = 50\n",
    "mu = np.linspace(0.,1.,Nmu)\n",
    "MU = np.tile(mu,Nk)\n",
    "dmu = list(mu[1:]-mu[:-1])\n",
    "dmu.append(dmu[-1])\n",
    "dmu = np.array(dmu)\n",
    "\n",
    "dk = list(k[1:]-k[:-1])\n",
    "dk.insert(0,dk[0])\n",
    "dk = np.array(dk)\n",
    "k = np.repeat(k,Nmu)\n",
    "dk = np.repeat(dk,Nmu)\n",
    "dmu = np.tile(dmu,Nk)\n",
    "\n",
    "ihod = 0\n",
    "print(simdata['mocks'][ihod]['hod'])\n",
    "dd = [simdata['mocks'][ihod]['pk0'],simdata['mocks'][ihod]['pk2']]\n",
    "dd = np.array(dd).T\n",
    "\n",
    "dvec = np.array([np.repeat(dd[:,0],Nmu),np.repeat(dd[:,1],Nmu)])\n",
    "d_pkmu = dvec[0]+0.5*(3*MU**2-1)*dvec[1]\n",
    "\n",
    "d_pkmu -= mSN[1]\n",
    "\n",
    "print(k.shape,d_pkmu.shape)\n",
    "Vsurvey = (1e3)**3\n",
    "\n",
    "prefactor = (2.*np.pi**2.) / (dk*dmu*Vsurvey*k**2.) * k**kpow\n",
    "Cov = prefactor*2*d_pkmu**2\n",
    "# constraints = forecast1.compute_wedge(z,kmin=kmin)*forecast1.kmax_constraint(z,kmax_knl)\n",
    "# constraints *= (forecast1.k > kmin)\n",
    "knl  = 0.5\n",
    "kmin = 0.003\n",
    "kmax = knl\n",
    "\n",
    "\n",
    "k_constraint = (k>kmin)*(k<kmax)\n",
    "Cov += 1e-20\n",
    "Cinv = 1/Cov\n",
    "Cinv *= k_constraint\n",
    "# Cinv = np.einsum('i,j,ij->ij',k_constraint,k_constraint,Cinv)\n",
    "\n",
    "# Cinv = np.ones(dvec.shape)\n",
    "\n",
    "file_name = 'data/sim_mm.json'\n",
    "\n",
    "save_dict = {'z':zz,'space':'rsd','kmin':kmin,'kmax':kmax,'Cov':Cov.tolist(),'Cinv':Cinv.tolist(),\n",
    "             'd_pkmu':d_pkmu.tolist(),'k':sim_k.tolist(),'mu':mu.tolist(),'d_ell':dd.tolist()}\n",
    "# Save array to JSON file\n",
    "with open(file_name, 'w') as json_file:\n",
    "    json.dump(save_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b266ace4-b6ef-4c27-b80f-062c7423f196",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d965e8b-3544-4d7b-892e-9df1173744de",
   "metadata": {},
   "source": [
    "# $z=2.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbe03e2-e3a7-4160-8c8b-6eea0e41a819",
   "metadata": {},
   "outputs": [],
   "source": [
    "zz = 2.5\n",
    "ihod = 1\n",
    "kpow = 1 # manual adjustment to covariance\n",
    "kpow = 1.5 # manual adjustment to covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6bcccc-3878-437e-b30e-95c66a97bc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ff = open('/pscratch/sd/h/hebina/AbacusLBG/ibis_tertiary44/LAE_auto/lae_clustering_concat_c000_ph100_s_zcv.json')\n",
    "ff = open('/pscratch/sd/h/hebina/AbacusLBG/ibis_tertiary44/LAE_auto_v2/hod/lae_clustering_c000_ph100_z2.5_s_zcv.json')\n",
    "# ff = open(self.datfn)\n",
    "simdata = json.load(ff)\n",
    "sim_k = np.array(simdata['k'])\n",
    "k = np.array(simdata['k'])\n",
    "Nk = len(k)\n",
    "Nmu = 50\n",
    "mu = np.linspace(0.,1.,Nmu)\n",
    "MU = np.tile(mu,Nk)\n",
    "dmu = list(mu[1:]-mu[:-1])\n",
    "dmu.append(dmu[-1])\n",
    "dmu = np.array(dmu)\n",
    "\n",
    "dk = list(k[1:]-k[:-1])\n",
    "dk.insert(0,dk[0])\n",
    "dk = np.array(dk)\n",
    "k = np.repeat(k,Nmu)\n",
    "dk = np.repeat(dk,Nmu)\n",
    "dmu = np.tile(dmu,Nk)\n",
    "\n",
    "print(simdata['mocks'][ihod]['hod'])\n",
    "dd = [simdata['mocks'][ihod]['pk0'],simdata['mocks'][ihod]['pk2']]\n",
    "dd = np.array(dd).T\n",
    "\n",
    "# take out shot noise\n",
    "true_SN = 1e9/min(simdata['mocks'][ihod]['nobj'],1e7)\n",
    "\n",
    "dvec = np.array([np.repeat(dd[:,0],Nmu),np.repeat(dd[:,1],Nmu)])\n",
    "d_pkmu = dvec[0]+0.5*(3*MU**2-1)*dvec[1]\n",
    "d_pkmu -= true_SN\n",
    "print(k.shape,d_pkmu.shape)\n",
    "Vsurvey = (1e3)**3\n",
    "\n",
    "prefactor = (2.*np.pi**2.) / (dk*dmu*Vsurvey*k**2.) * k**kpow\n",
    "Cov = prefactor*2*d_pkmu**2\n",
    "# constraints = forecast1.compute_wedge(z,kmin=kmin)*forecast1.kmax_constraint(z,kmax_knl)\n",
    "# constraints *= (forecast1.k > kmin)\n",
    "knl  = 0.5\n",
    "kmin = 0.003\n",
    "kmax = knl\n",
    "\n",
    "\n",
    "k_constraint = (k>kmin)*(k<kmax)\n",
    "Cov += 1e-20\n",
    "Cinv = 1/Cov\n",
    "Cinv *= k_constraint\n",
    "# Cinv = np.einsum('i,j,ij->ij',k_constraint,k_constraint,Cinv)\n",
    "\n",
    "# Cinv = np.ones(dvec.shape)\n",
    "\n",
    "\n",
    "file_name = 'data/sim_gg.json'\n",
    "\n",
    "save_dict = {'z':zz,'space':'rsd','kmin':kmin,'kmax':kmax,'Cov':Cov.tolist(),'Cinv':Cinv.tolist(),\n",
    "             'd_pkmu':d_pkmu.tolist(),'k':sim_k.tolist(),'mu':mu.tolist(),'d_ell':dd.tolist()}\n",
    "# Save array to JSON file\n",
    "with open(file_name, 'w') as json_file:\n",
    "    json.dump(save_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1f52ff-30e3-4a80-9fb2-b2cb74cef535",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ff = open('/pscratch/sd/h/hebina/AbacusLBG/ibis_tertiary44/LAE_auto/lae_clustering_concat_c000_ph100_s_zcv.json')\n",
    "ff = open('/pscratch/sd/h/hebina/AbacusLBG/ibis_tertiary44/LAE_auto_v2/hod/lae_clustering_c000_ph100_z2.5_r_zcv.json')\n",
    "# ff = open(self.datfn)\n",
    "simdata = json.load(ff)\n",
    "sim_k = np.array(simdata['k'])\n",
    "k = np.array(simdata['k'])\n",
    "Nk = len(k)\n",
    "Nmu = 50\n",
    "mu = np.linspace(0.,1.,Nmu)\n",
    "MU = np.tile(mu,Nk)\n",
    "dmu = list(mu[1:]-mu[:-1])\n",
    "dmu.append(dmu[-1])\n",
    "dmu = np.array(dmu)\n",
    "\n",
    "dk = list(k[1:]-k[:-1])\n",
    "dk.insert(0,dk[0])\n",
    "dk = np.array(dk)\n",
    "k = np.repeat(k,Nmu)\n",
    "dk = np.repeat(dk,Nmu)\n",
    "dmu = np.tile(dmu,Nk)\n",
    "\n",
    "print(simdata['mocks'][ihod]['hod'])\n",
    "dd = [simdata['mocks'][ihod]['pk0'],simdata['mocks'][ihod]['pk2']]\n",
    "dd = np.array(dd).T\n",
    "\n",
    "# take out shot noise\n",
    "true_SN = 1e9/min(simdata['mocks'][ihod]['nobj'],1e7)\n",
    "\n",
    "dvec = np.array([np.repeat(dd[:,0],Nmu),np.repeat(dd[:,1],Nmu)])\n",
    "d_pkmu = dvec[0]+0.5*(3*MU**2-1)*dvec[1]\n",
    "d_pkmu -= true_SN\n",
    "print(k.shape,d_pkmu.shape)\n",
    "Vsurvey = (1e3)**3\n",
    "\n",
    "prefactor = (2.*np.pi**2.) / (dk*dmu*Vsurvey*k**2.) * k**kpow\n",
    "Cov = prefactor*2*d_pkmu**2\n",
    "# constraints = forecast1.compute_wedge(z,kmin=kmin)*forecast1.kmax_constraint(z,kmax_knl)\n",
    "# constraints *= (forecast1.k > kmin)\n",
    "knl  = 0.5\n",
    "kmin = 0.003\n",
    "kmax = knl\n",
    "\n",
    "\n",
    "k_constraint = (k>kmin)*(k<kmax)\n",
    "Cov += 1e-20\n",
    "Cinv = 1/Cov\n",
    "Cinv *= k_constraint\n",
    "# Cinv = np.einsum('i,j,ij->ij',k_constraint,k_constraint,Cinv)\n",
    "\n",
    "# Cinv = np.ones(dvec.shape)\n",
    "\n",
    "\n",
    "file_name = 'data/sim_gg_real.json'\n",
    "\n",
    "save_dict = {'z':zz,'space':'rsd','kmin':kmin,'kmax':kmax,'Cov':Cov.tolist(),'Cinv':Cinv.tolist(),\n",
    "             'd_pkmu':d_pkmu.tolist(),'k':sim_k.tolist(),'mu':mu.tolist(),'d_ell':dd.tolist()}\n",
    "# Save array to JSON file\n",
    "with open(file_name, 'w') as json_file:\n",
    "    json.dump(save_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68847675-71e4-48a0-972d-88dc464b5332",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ff = open('/pscratch/sd/h/hebina/AbacusLBG/ibis_tertiary44/LAE_auto/lae_clustering_concat_c000_ph100_s_zcv.json')\n",
    "ff = open('/pscratch/sd/h/hebina/AbacusLBG/ibis_tertiary44/LAE_auto_v2/hod/lae_clustering_c000_ph100_z2.5_r_gm.json')\n",
    "# ff = open(self.datfn)\n",
    "simdata = json.load(ff)\n",
    "sim_k = np.array(simdata['k'])\n",
    "k = np.array(simdata['k'])\n",
    "Nk = len(k)\n",
    "Nmu = 50\n",
    "mu = np.linspace(0.,1.,Nmu)\n",
    "MU = np.tile(mu,Nk)\n",
    "dmu = list(mu[1:]-mu[:-1])\n",
    "dmu.append(dmu[-1])\n",
    "dmu = np.array(dmu)\n",
    "\n",
    "dk = list(k[1:]-k[:-1])\n",
    "dk.insert(0,dk[0])\n",
    "dk = np.array(dk)\n",
    "k = np.repeat(k,Nmu)\n",
    "dk = np.repeat(dk,Nmu)\n",
    "dmu = np.tile(dmu,Nk)\n",
    "\n",
    "print(simdata['mocks'][ihod]['hod'])\n",
    "dd = [simdata['mocks'][ihod]['pk0'],simdata['mocks'][ihod]['pk2']]\n",
    "dd = np.array(dd).T\n",
    "\n",
    "# dvec = np.array([np.repeat(dd[:,0],Nmu),np.repeat(dd[:,1],Nmu),np.repeat(dd[:,2],Nmu)])\n",
    "# d_pkmu = dvec[0]+0.5*(3*MU**2-1)*dvec[1]+0.125*(35*MU**4-30*MU**2+3)*dvec[2]\n",
    "dvec = np.array([np.repeat(dd[:,0],Nmu),np.repeat(dd[:,1],Nmu)])\n",
    "d_pkmu = dvec[0]+0.5*(3*MU**2-1)*dvec[1]\n",
    "print(k.shape,d_pkmu.shape)\n",
    "Vsurvey = (1e3)**3\n",
    "\n",
    "prefactor = (2.*np.pi**2.) / (dk*dmu*Vsurvey*k**2.) * k**kpow\n",
    "Cov = prefactor*2*d_pkmu**2\n",
    "# constraints = forecast1.compute_wedge(z,kmin=kmin)*forecast1.kmax_constraint(z,kmax_knl)\n",
    "# constraints *= (forecast1.k > kmin)\n",
    "knl  = 0.5\n",
    "kmin = 0.003\n",
    "kmax = knl\n",
    "\n",
    "\n",
    "k_constraint = (k>kmin)*(k<kmax)\n",
    "Cov += 1e-20\n",
    "Cinv = 1/Cov\n",
    "Cinv *= k_constraint\n",
    "# Cinv = np.einsum('i,j,ij->ij',k_constraint,k_constraint,Cinv)\n",
    "\n",
    "# Cinv = np.ones(dvec.shape)\n",
    "\n",
    "file_name = 'data/sim_gm.json'\n",
    "\n",
    "save_dict = {'z':zz,'space':'rsd','kmin':kmin,'kmax':kmax,'Cov':Cov.tolist(),'Cinv':Cinv.tolist(),\n",
    "             'd_pkmu':d_pkmu.tolist(),'k':sim_k.tolist(),'mu':mu.tolist(),'d_ell':dd.tolist()}\n",
    "# Save array to JSON file\n",
    "with open(file_name, 'w') as json_file:\n",
    "    json.dump(save_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7dc6d3-0775-4df0-8a45-60cc82ba90e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ff = open('/pscratch/sd/h/hebina/AbacusLBG/ibis_tertiary44/LAE_auto/lae_clustering_concat_c000_ph100_s_zcv.json')\n",
    "ff = open('/pscratch/sd/h/hebina/AbacusLBG/ibis_tertiary44/LAE_auto_v2/hod/lae_clustering_c000_ph100_z2.5_r_mm.json')\n",
    "# ff = open(self.datfn)\n",
    "simdata = json.load(ff)\n",
    "sim_k = np.array(simdata['k'])\n",
    "k = np.array(simdata['k'])\n",
    "Nk = len(k)\n",
    "Nmu = 50\n",
    "mu = np.linspace(0.,1.,Nmu)\n",
    "MU = np.tile(mu,Nk)\n",
    "dmu = list(mu[1:]-mu[:-1])\n",
    "dmu.append(dmu[-1])\n",
    "dmu = np.array(dmu)\n",
    "\n",
    "dk = list(k[1:]-k[:-1])\n",
    "dk.insert(0,dk[0])\n",
    "dk = np.array(dk)\n",
    "k = np.repeat(k,Nmu)\n",
    "dk = np.repeat(dk,Nmu)\n",
    "dmu = np.tile(dmu,Nk)\n",
    "\n",
    "ihod = 0\n",
    "print(simdata['mocks'][ihod]['hod'])\n",
    "dd = [simdata['mocks'][ihod]['pk0'],simdata['mocks'][ihod]['pk2']]\n",
    "dd = np.array(dd).T\n",
    "\n",
    "# dvec = np.array([np.repeat(dd[:,0],Nmu),np.repeat(dd[:,1],Nmu),np.repeat(dd[:,2],Nmu)])\n",
    "# d_pkmu = dvec[0]+0.5*(3*MU**2-1)*dvec[1]+0.125*(35*MU**4-30*MU**2+3)*dvec[2]\n",
    "dvec = np.array([np.repeat(dd[:,0],Nmu),np.repeat(dd[:,1],Nmu)])\n",
    "d_pkmu = dvec[0]+0.5*(3*MU**2-1)*dvec[1]\n",
    "d_pkmu -= mSN[0]\n",
    "print(k.shape,d_pkmu.shape)\n",
    "Vsurvey = (1e3)**3\n",
    "\n",
    "prefactor = (2.*np.pi**2.) / (dk*dmu*Vsurvey*k**2.) * k**kpow\n",
    "Cov = prefactor*2*d_pkmu**2\n",
    "# constraints = forecast1.compute_wedge(z,kmin=kmin)*forecast1.kmax_constraint(z,kmax_knl)\n",
    "# constraints *= (forecast1.k > kmin)\n",
    "knl  = 0.5\n",
    "kmin = 0.003\n",
    "kmax = knl\n",
    "\n",
    "\n",
    "k_constraint = (k>kmin)*(k<kmax)\n",
    "Cov += 1e-20\n",
    "Cinv = 1/Cov\n",
    "Cinv *= k_constraint\n",
    "# Cinv = np.einsum('i,j,ij->ij',k_constraint,k_constraint,Cinv)\n",
    "\n",
    "# Cinv = np.ones(dvec.shape)\n",
    "\n",
    "file_name = 'data/sim_mm.json'\n",
    "\n",
    "save_dict = {'z':zz,'space':'rsd','kmin':kmin,'kmax':kmax,'Cov':Cov.tolist(),'Cinv':Cinv.tolist(),\n",
    "             'd_pkmu':d_pkmu.tolist(),'k':sim_k.tolist(),'mu':mu.tolist(),'d_ell':dd.tolist()}\n",
    "# Save array to JSON file\n",
    "with open(file_name, 'w') as json_file:\n",
    "    json.dump(save_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2991a0-0709-4b54-8d44-783b97c84f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2ffb59-1ef9-4c14-b758-5c967750693a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
